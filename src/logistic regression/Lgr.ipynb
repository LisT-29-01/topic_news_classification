{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from unidecode import unidecode\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn import preprocessing\n",
    "\n",
    "#%cd /content/vietnamese_news_ml_dl\n",
    "# training data: \n",
    "path = r'/content/vietnamese_news_ml_dl/10topics_update_final/train_0.8'\n",
    "X_train10 = []\n",
    "Y_train10 = []\n",
    "# for train10_origin\n",
    "for topic in os.listdir(path):\n",
    "  pd = os.path.join(path, topic)\n",
    "  for file in os.listdir(pd):\n",
    "    pf = os.path.join(pd, file)\n",
    "    text = open(pf, 'r').read()\n",
    "    # words = text.split()\n",
    "    \n",
    "    text = unidecode(text) # test sử dụng câu bỏ dấu\n",
    "\n",
    "    X_train10.append(text)\n",
    "    Y_train10.append(topic)\n",
    "\n",
    "# test data: \n",
    "path = r'/content/vietnamese_news_ml_dl/10topics_update_final/test10_origin_processed'\n",
    "X_test10 = []\n",
    "Y_test10 = []\n",
    "# for train10_origin\n",
    "for topic in os.listdir(path):\n",
    "  pd = os.path.join(path, topic)\n",
    "  for file in os.listdir(pd):\n",
    "    pf = os.path.join(pd, file)\n",
    "    text = open(pf, 'r').read()\n",
    "    # words = text.split()\n",
    "  \n",
    "    text = unidecode(text) # test sử dụng câu bỏ dấu\n",
    "\n",
    "    X_test10.append(text)\n",
    "    Y_test10.append(topic)\n",
    "\n",
    "#valid data\n",
    "path = r'/content/vietnamese_news_ml_dl/10topics_update_final/valid_0.8'\n",
    "X_valid10 = []\n",
    "Y_valid10 = []\n",
    "for topic in os.listdir(path):\n",
    "  pd = os.path.join(path, topic)\n",
    "  for file in os.listdir(pd):\n",
    "    pf = os.path.join(pd, file)\n",
    "    text = open(pf, 'r').read()\n",
    "    # words = text.split()\n",
    "  \n",
    "    text = unidecode(text) # test sử dụng câu bỏ dấu\n",
    "\n",
    "    X_valid10.append(text)\n",
    "    Y_valid10.append(topic)\n",
    "\n",
    "count_vector = CountVectorizer()\n",
    "X_train_tranform10 = count_vector.fit(X_train10)\n",
    "X_train_tranform10 = count_vector.transform(X_train10)\n",
    "# label encoder\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(Y_train10)\n",
    "Y_train_transform10 = le.transform(Y_train10)\n",
    "\n",
    "#for test data\n",
    "X_valid_transform10 = count_vector.transform(X_valid10)\n",
    "Y_valid_transform10 = le.transform(Y_valid10)\n",
    "\n",
    "# for test data\n",
    "X_test_transform10 = count_vector.transform(X_test10)\n",
    "Y_test_transform10 = le.transform(Y_test10)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for Tfidf \n",
    "tf_transformer = TfidfTransformer(use_idf=False).fit(X_train_tranform10)\n",
    "X_train10_tf = tf_transformer.transform(X_train_tranform10)\n",
    "X_valid10_tf = tf_transformer.transform(X_valid_transform10)\n",
    "X_test10_tf = tf_transformer.transform(X_test_transform10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Turning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "import time\n",
    "for x in range(15,30):\n",
    "  start = time.time()\n",
    "  model_lgr_count = LogisticRegression(random_state=0, max_iter=x)\n",
    "  model_lgr_count.fit(X_tranform10, Y_transform10)\n",
    "  end = time.time()\n",
    "  y_predict_train_lgr = model_lgr_count.predict(X_tranform10)\n",
    "  y_predict_valid_lgr = model_lgr_count.predict(X_valid_transform10)\n",
    "  print(\"inter = \" ,x)\n",
    "  print(\"acc per train :\" , accuracy_score(y_predict_train_lgr, Y_transform10))\n",
    "  print(\"acc per valid :\" , accuracy_score(y_predict_valid_lgr,Y_valid_transform10))\n",
    "  print(\"training time: \", end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in range(20,60):\n",
    "  start = time.time()\n",
    "  model_lgr_count = LogisticRegression(random_state=0, max_iter=x)\n",
    "  model_lgr_count.fit(X_train10_tf, Y_transform10)\n",
    "  end = time.time()\n",
    "  y_predict_train_lgr = model_lgr_count.predict(X_train10_tf)\n",
    "  y_predict_valid_lgr = model_lgr_count.predict(X_valid10_tf)\n",
    "  print(\"inter = \" ,x)\n",
    "  print(\"acc per train :\" , accuracy_score(y_predict_train_lgr, Y_transform10))\n",
    "  print(\"acc per valid :\" , accuracy_score(y_predict_valid_lgr,Y_valid_transform10))\n",
    "  print(\"training time: \", end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test and save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import time\n",
    "start = time.time()\n",
    "model_lgr_count = LogisticRegression(random_state=0, max_iter=22)\n",
    "model_lgr_count.fit(X_tranform10, Y_transform10)\n",
    "end = time.time()\n",
    "\n",
    "y_predict_train_lgr = model_lgr_count.predict(X_tranform10)\n",
    "y_predict_valid_lgr = model_lgr_count.predict(X_valid_transform10)\n",
    "\n",
    "print(\"acc per train :\" , accuracy_score(y_predict_train_lgr, Y_transform10))\n",
    "print(\"acc per valid :\" , accuracy_score(y_predict_valid_lgr,Y_valid_transform10))\n",
    "print(\"training time: \", end - start)\n",
    "\n",
    "confusion_matrix(y_predict_test_lgr,Y_test_transform10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump, load\n",
    "dump(model_lgr_count,\"logisticsRegression.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kflod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "num_folds = 10\n",
    "acc_per_fold = []\n",
    "kfold = KFold(n_splits=num_folds, shuffle=True)\n",
    "fold_no = 1\n",
    "for train, valid in kfold.split(X_tranform10,Y_transform10):\n",
    "  metric = []\n",
    "  model_lgr_count = LogisticRegression(random_state=0, max_iter=22)\n",
    "  print('------------------------------------------------------------------------')\n",
    "  print(f'Training for fold {fold_no} ...')\n",
    "  model_lgr_count.fit(X_tranform10[train],Y_transform10[train])\n",
    "\n",
    "  y_predict_train_lgr = model_lgr_count.predict(X_tranform10[train])\n",
    "  score1 = accuracy_score(Y_transform10[train], y_predict_train_lgr)\n",
    "\n",
    "  y_predict_valid_lgr = model_lgr_count.predict(X_tranform10[valid])\n",
    "  score2 = accuracy_score(Y_transform10[valid],y_predict_valid_lgr)\n",
    "\n",
    "  y_predict_test_lgr = model_lgr_count.predict(X_test_transform10)\n",
    "  score3 = accuracy_score(Y_test_transform10,y_predict_test_lgr)\n",
    "  metric.append([score1,score2,score3])\n",
    "  print(f'Score for fold {fold_no}: on train: {score1}    on valid: {score2}    on test: {score3}')\n",
    "  acc_per_fold.append(metric)\n",
    "  fold_no += 1\n",
    "\n",
    "acc_per_fold"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}